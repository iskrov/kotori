# Alembic Migration Guide

## Overview

This project uses Alembic for database schema migrations. Alembic is properly configured with environment support and all models are imported for autogeneration.

## Configuration

### Directory Structure
```
backend/
├── migrations/
│   ├── env.py          # Alembic environment configuration
│   ├── script.py.mako  # Migration template
│   └── versions/       # Migration files
└── alembic.ini         # Alembic configuration
```

### Environment Setup

Alembic is configured to use the `DATABASE_URL` from environment variables through `app.core.config.settings`:

```python
# In migrations/env.py
from app.core.config import settings
config.set_main_option("sqlalchemy.url", settings.DATABASE_URL)
```

### Model Detection

All models are imported in `migrations/env.py` to ensure Alembic can detect schema changes:

```python
# Import all models for Alembic to detect
from app.models.user import User
from app.models.journal_entry import JournalEntry
from app.models.tag import Tag, JournalEntryTag
from app.models.reminder import Reminder
from app.models.secret_tag_opaque import (
    SecretTag, WrappedKey, VaultBlob, OpaqueSession,
    SecurityAuditLog, SecurityMetrics, SecurityAlert
)
from app.models.monitoring import (
    SystemHealth, ServiceHealth, Alert, AlertRule, AlertChannel,
    AlertEscalation, MonitoringConfiguration, MonitoringMetric,
    MonitoringDashboard
)
```

## Migration Commands

### Check Current Migration Status
```bash
alembic current
```

### View Migration History
```bash
alembic history --verbose
```

### Check for Pending Changes
```bash
alembic check
```

### Create a New Migration
```bash
# Auto-generate migration from model changes
alembic revision --autogenerate -m "Description of changes"

# Create empty migration (for data migrations)
alembic revision -m "Description of changes"
```

### Apply Migrations
```bash
# Upgrade to latest
alembic upgrade head

# Upgrade to specific revision
alembic upgrade <revision_id>

# Downgrade to specific revision
alembic downgrade <revision_id>
```

## Best Practices

### 1. Migration Creation
- Always use descriptive migration messages
- Review auto-generated migrations before applying
- Test migrations on development database first
- Include both upgrade and downgrade operations

### 2. Schema Changes
- Use `op.create_table()` for new tables
- Use `op.add_column()` for new columns with proper defaults
- Use `op.create_index()` for new indexes
- Use `op.drop_constraint()` before `op.drop_column()`

### 3. Data Migration
- Use `op.execute()` for SQL statements
- Use `op.get_bind()` for SQLAlchemy operations
- Always provide rollback procedures
- Handle large datasets in batches

### 4. Index Management
- Create indexes for all foreign key columns
- Use composite indexes for common query patterns
- Add unique constraints for business rules
- Consider partial indexes for filtered queries

### 5. Testing
- Test migrations in development environment
- Test rollback procedures
- Verify data integrity after migration
- Check query performance with new indexes

## Environment Support

The configuration supports multiple environments:

- **Development**: Uses local PostgreSQL database
- **Test**: Uses test database configuration
- **Production**: Uses production database URL

Environment-specific configuration is handled through environment variables:

```bash
# Development
DATABASE_URL=postgresql://postgres:password@localhost:5432/vibes_db

# Test
DATABASE_URL=postgresql://postgres:password@localhost:5432/vibes_test_db

# Production
DATABASE_URL=postgresql://user:password@prod-host:5432/vibes_prod_db
```

## Migration Example

### Auto-generated Migration
```python
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('new_table',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(length=100), nullable=False),
        sa.Column('user_id', sa.UUID(), nullable=False),
        sa.Column('created_at', sa.DateTime(timezone=True), 
                  server_default=sa.text('now()'), nullable=False),
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id']),
    )
    op.create_index(op.f('ix_new_table_user_id'), 'new_table', ['user_id'])
    # ### end Alembic commands ###

def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_new_table_user_id'), table_name='new_table')
    op.drop_table('new_table')
    # ### end Alembic commands ###
```

### Custom Data Migration
```python
def upgrade() -> None:
    # Create connection for data operations
    connection = op.get_bind()
    
    # Add new column
    op.add_column('users', sa.Column('full_name', sa.String(255), nullable=True))
    
    # Migrate existing data
    connection.execute(
        text("UPDATE users SET full_name = first_name || ' ' || last_name WHERE first_name IS NOT NULL")
    )
    
    # Drop old columns
    op.drop_column('users', 'first_name')
    op.drop_column('users', 'last_name')

def downgrade() -> None:
    # Add back old columns
    op.add_column('users', sa.Column('first_name', sa.String(100), nullable=True))
    op.add_column('users', sa.Column('last_name', sa.String(100), nullable=True))
    
    # Restore data
    connection = op.get_bind()
    connection.execute(
        text("UPDATE users SET first_name = split_part(full_name, ' ', 1), last_name = split_part(full_name, ' ', 2)")
    )
    
    # Drop new column
    op.drop_column('users', 'full_name')
```

## Troubleshooting

### Common Issues

1. **Import Errors**: Ensure all models are imported in `migrations/env.py`
2. **Database Connection**: Check `DATABASE_URL` environment variable
3. **Migration Conflicts**: Use `alembic merge` to resolve conflicts
4. **Data Type Issues**: Review PostgreSQL-specific type handling

### Recovery Procedures

1. **Failed Migration**: Use `alembic downgrade` to rollback
2. **Corrupt Migration History**: Use `alembic stamp` to fix history
3. **Schema Drift**: Use `alembic revision --autogenerate` to sync

## Performance Considerations

- Create indexes for foreign keys and frequently queried columns
- Use partial indexes for filtered queries
- Consider index maintenance during large data migrations
- Monitor query performance after schema changes

## Security

- Never include sensitive data in migration files
- Use environment variables for database credentials
- Review auto-generated migrations before applying
- Backup database before running migrations in production

## Clean Schema Creation

For development environments, you can create a clean schema from scratch without accumulated migration history:

### When to Use Clean Schema Creation
- Development environment reset
- Starting fresh without migration history
- Consolidating multiple migrations into a single baseline
- Removing legacy migration artifacts

### Process
1. **Drop and recreate database** (development only)
2. **Remove existing migrations** from `migrations/versions/`
3. **Generate single initial migration** from current model state
4. **Apply clean migration** to create optimized schema

### Results
- **Single migration file** instead of multiple accumulated migrations
- **Clean schema** with all optimizations built-in
- **No legacy artifacts** from previous migration patches
- **Optimized indexes and constraints** from the start

### Example Clean Schema Results
```
✅ Created 22 tables:
  - alembic_version, alert_channels, alert_escalations, alert_rules, alerts
  - journal_entries, journal_entry_tags, monitoring_configuration
  - monitoring_dashboards, monitoring_metrics, opaque_sessions
  - reminders, secret_tags, security_alerts, security_audit_logs
  - security_metrics, service_health, system_health, tags
  - users, vault_blobs, wrapped_keys

✅ Current migration version: 2c88eb7b741c (head)
✅ Created 126 indexes (includes all performance optimizations)
```

### Clean Migration History
```
Rev: 2c88eb7b741c (head)
Parent: <base>
Path: migrations/versions/2c88eb7b741c_initial_schema_with_optimized_indexes_.py
    Initial schema with optimized indexes and constraints
```

**⚠️ Warning**: Only use clean schema creation in development environments. Production environments should use incremental migrations to preserve data. 