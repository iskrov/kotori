# [9-5] Optimize decryption performance with caching

## Description

Implement a caching layer for decrypted journal entries to avoid repeated decryption operations. This will significantly improve performance when viewing lists of entries or navigating between screens.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-08-12 03:30:00 | Created | N/A | Proposed | Task created for performance optimization | ai-agent |

## Requirements

### Functional Requirements
1. Cache decrypted content in memory
2. Invalidate cache on entry updates
3. Limit cache size to prevent memory issues
4. Clear cache on logout
5. Optional persistent cache for offline access

### Technical Requirements
1. LRU (Least Recently Used) cache implementation
2. Cache key based on entry ID and version
3. Memory limit of 10MB for cache
4. Cache statistics for monitoring
5. Thread-safe cache operations

## Implementation Plan

### Step 1: Implement LRU Cache
```typescript
// Create new file: frontend/src/utils/LRUCache.ts
export class LRUCache<K, V> {
  private maxSize: number;
  private maxBytes: number;
  private cache: Map<K, { value: V; size: number; timestamp: number }>;
  private accessOrder: K[];
  private currentBytes: number;
  
  constructor(maxSize: number = 100, maxBytes: number = 10 * 1024 * 1024) {
    this.maxSize = maxSize;
    this.maxBytes = maxBytes;
    this.cache = new Map();
    this.accessOrder = [];
    this.currentBytes = 0;
  }
  
  get(key: K): V | undefined {
    const entry = this.cache.get(key);
    if (entry) {
      // Move to end (most recently used)
      this.updateAccessOrder(key);
      return entry.value;
    }
    return undefined;
  }
  
  set(key: K, value: V, sizeBytes: number): void {
    // Remove if exists
    if (this.cache.has(key)) {
      this.remove(key);
    }
    
    // Check size limits
    while (
      (this.cache.size >= this.maxSize || 
       this.currentBytes + sizeBytes > this.maxBytes) &&
      this.accessOrder.length > 0
    ) {
      // Remove least recently used
      const lru = this.accessOrder.shift()!;
      this.remove(lru);
    }
    
    // Add new entry
    this.cache.set(key, {
      value,
      size: sizeBytes,
      timestamp: Date.now()
    });
    this.accessOrder.push(key);
    this.currentBytes += sizeBytes;
  }
  
  remove(key: K): boolean {
    const entry = this.cache.get(key);
    if (entry) {
      this.cache.delete(key);
      this.accessOrder = this.accessOrder.filter(k => k !== key);
      this.currentBytes -= entry.size;
      return true;
    }
    return false;
  }
  
  clear(): void {
    this.cache.clear();
    this.accessOrder = [];
    this.currentBytes = 0;
  }
  
  getStats(): CacheStats {
    return {
      size: this.cache.size,
      maxSize: this.maxSize,
      bytesUsed: this.currentBytes,
      maxBytes: this.maxBytes,
      hitRate: this.calculateHitRate()
    };
  }
}
```

### Step 2: Create Decryption Cache Service
```typescript
// Create new file: frontend/src/services/decryptionCache.ts
import { LRUCache } from '../utils/LRUCache';

class DecryptionCacheService {
  private cache: LRUCache<string, DecryptedEntry>;
  private hits: number = 0;
  private misses: number = 0;
  
  constructor() {
    this.cache = new LRUCache<string, DecryptedEntry>(
      100, // max 100 entries
      10 * 1024 * 1024 // max 10MB
    );
  }
  
  getCacheKey(entry: JournalEntry): string {
    // Include updated_at to invalidate on changes
    return `${entry.id}_${entry.updated_at}`;
  }
  
  async getDecrypted(
    entry: JournalEntry,
    decryptFn: (entry: JournalEntry) => Promise<string>
  ): Promise<JournalEntry> {
    const cacheKey = this.getCacheKey(entry);
    
    // Check cache first
    const cached = this.cache.get(cacheKey);
    if (cached) {
      this.hits++;
      logger.debug(`Cache hit for entry ${entry.id}`);
      return cached;
    }
    
    this.misses++;
    logger.debug(`Cache miss for entry ${entry.id}`);
    
    // Decrypt and cache
    try {
      const decryptedContent = await decryptFn(entry);
      const decryptedEntry = {
        ...entry,
        content: decryptedContent,
        encrypted_content: undefined,
        wrapped_key: undefined
      };
      
      // Estimate size (rough calculation)
      const size = JSON.stringify(decryptedEntry).length;
      
      this.cache.set(cacheKey, decryptedEntry, size);
      return decryptedEntry;
    } catch (error) {
      logger.error('Decryption failed, not caching', error);
      throw error;
    }
  }
  
  invalidateEntry(entryId: string): void {
    // Remove all versions of this entry
    const keysToRemove = Array.from(this.cache.keys())
      .filter(key => key.startsWith(`${entryId}_`));
    
    keysToRemove.forEach(key => this.cache.remove(key));
  }
  
  invalidateAll(): void {
    this.cache.clear();
    this.resetStats();
  }
  
  getStats(): CacheStatistics {
    const cacheStats = this.cache.getStats();
    return {
      ...cacheStats,
      hits: this.hits,
      misses: this.misses,
      hitRate: this.hits / (this.hits + this.misses) || 0
    };
  }
  
  private resetStats(): void {
    this.hits = 0;
    this.misses = 0;
  }
}

export const decryptionCache = new DecryptionCacheService();
```

### Step 3: Integrate Cache with encryptedJournalService
```typescript
// Update encryptedJournalService.ts
import { decryptionCache } from './decryptionCache';

class EncryptedJournalService {
  async processEntries(entries: any[]): Promise<JournalEntryData[]> {
    const processed = await Promise.all(
      entries.map(async (entry) => {
        if (entry.is_encrypted && entry.encrypted_content) {
          // Use cache for decryption
          return decryptionCache.getDecrypted(
            entry,
            async (e) => this.decryptEntry(e)
          );
        }
        return entry;
      })
    );
    
    return processed;
  }
  
  async updateEntry(
    entryId: string,
    data: Partial<JournalEntryData>
  ): Promise<JournalEntryData> {
    // Invalidate cache for this entry
    decryptionCache.invalidateEntry(entryId);
    
    // Proceed with update
    const updated = await this.performUpdate(entryId, data);
    
    // Pre-cache the updated entry if encrypted
    if (updated.is_encrypted) {
      await decryptionCache.getDecrypted(
        updated,
        async (e) => this.decryptEntry(e)
      );
    }
    
    return updated;
  }
  
  async deleteEntry(entryId: string): Promise<void> {
    // Invalidate cache
    decryptionCache.invalidateEntry(entryId);
    
    // Proceed with deletion
    await this.performDelete(entryId);
  }
}
```

### Step 4: Add Cache Management UI
```typescript
// Add to settings or debug screen
export const CacheManagement: React.FC = () => {
  const [stats, setStats] = useState<CacheStatistics | null>(null);
  
  useEffect(() => {
    const interval = setInterval(() => {
      setStats(decryptionCache.getStats());
    }, 5000);
    
    return () => clearInterval(interval);
  }, []);
  
  const clearCache = () => {
    decryptionCache.invalidateAll();
    Alert.alert('Cache Cleared', 'Decryption cache has been cleared');
  };
  
  if (!stats) return null;
  
  return (
    <View style={styles.container}>
      <Text style={styles.title}>Decryption Cache</Text>
      <Text>Entries: {stats.size}/{stats.maxSize}</Text>
      <Text>Memory: {formatBytes(stats.bytesUsed)}/{formatBytes(stats.maxBytes)}</Text>
      <Text>Hit Rate: {(stats.hitRate * 100).toFixed(1)}%</Text>
      <TouchableOpacity onPress={clearCache}>
        <Text style={styles.clearButton}>Clear Cache</Text>
      </TouchableOpacity>
    </View>
  );
};
```

### Step 5: Add Persistent Cache (Optional)
```typescript
// Add persistent cache for offline access
class PersistentDecryptionCache {
  private memoryCache: DecryptionCacheService;
  private storageKey = 'decryption_cache_v1';
  
  async loadFromStorage(): Promise<void> {
    try {
      const stored = await AsyncStorage.getItem(this.storageKey);
      if (stored) {
        const entries = JSON.parse(stored);
        // Validate and load into memory cache
        for (const entry of entries) {
          if (this.isValid(entry)) {
            this.memoryCache.set(entry.key, entry.value, entry.size);
          }
        }
      }
    } catch (error) {
      logger.error('Failed to load cache from storage', error);
    }
  }
  
  async saveToStorage(): Promise<void> {
    try {
      const entries = this.memoryCache.getAll();
      await AsyncStorage.setItem(
        this.storageKey,
        JSON.stringify(entries)
      );
    } catch (error) {
      logger.error('Failed to save cache to storage', error);
    }
  }
  
  private isValid(entry: CachedEntry): boolean {
    // Check if entry is still valid (not expired, etc.)
    const age = Date.now() - entry.timestamp;
    return age < 24 * 60 * 60 * 1000; // 24 hours
  }
}
```

## Verification

### Performance Testing
1. Measure decryption time without cache (baseline)
2. Measure with cache (should be ~100x faster for cached entries)
3. Test cache eviction with many entries
4. Test memory usage stays within limits
5. Test cache invalidation on updates

### Success Criteria
- [ ] Cache hit rate > 80% for typical usage
- [ ] List scrolling smooth with 50+ encrypted entries
- [ ] Memory usage stays under 10MB
- [ ] Cache properly invalidates on updates
- [ ] No memory leaks detected

## Files Modified

Expected files to create/modify:
- `frontend/src/utils/LRUCache.ts` (new)
- `frontend/src/services/decryptionCache.ts` (new)
- `frontend/src/services/encryptedJournalService.ts`
- `frontend/src/screens/settings/CacheManagement.tsx` (new, optional)
- `frontend/src/types/cache.ts` (new)

## Notes

This optimization is crucial for providing a smooth user experience, especially when dealing with lists of encrypted entries. The cache should be transparent to the user but provide significant performance improvements.

[Back to task list](./tasks.md)
